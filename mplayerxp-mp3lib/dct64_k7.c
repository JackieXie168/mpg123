/*
 Replacement of dct64() with AMD's 3DNowEx(DSP)! SIMD operations support

 This code based 'dct64_3dnow.s' by Syuuhei Kashiyama
 <squash@mb.kcom.ne.jp>,only some types of changes have been made:

  - added new opcodes PSWAPD, PFPNACC
  - decreased number of opcodes (as it was suggested by k7 manual)
    (using memory reference as operand of instructions)
  - Phase 6 is rewritten with mixing of cpu and mmx opcodes
  - change function name for support 3DNowEx! automatic detect
  - negation of 3dnow reg was replaced with PXOR 0x800000000, MMi instead
    of PFMUL as it was suggested by athlon manual. (Two not separated PFMUL
    can not be paired, but PXOR can be).

 note: because K7 processors are an aggresive out-of-order three-way
       superscalar ones instruction order is not significand for them.

 Modified by Nick Kurshev <nickols_k@mail.ru>

 The author of this program disclaim whole expressed or implied
 warranties with regard to this program, and in no event shall the
 author of this program liable to whatever resulted from the use of
 this program. Use it at your own risk.

*/
#include "../../mplayerxp/mangle.h"
typedef float real;

static unsigned  __attribute__((used)) __attribute__((__aligned__(8))) plus_minus_3dnow[2] = { 0x00000000UL, 0x80000000UL };
/* Discrete Cosine Tansform (DCT) for subband synthesis */
void dct64_3dnowex(real *a,real *b,real *c)
{
	char tmp[256];
	__asm __volatile("femms":::"memory");
	__asm __volatile(
"	// 1\n\t"
"	movl "MANGLE(pnts)",%%eax\n\t"

"	movq 0(%3),%%mm0        /* mm0 = c[0x00] | c[0x01]*/\n\t"
"	movq %%mm0,%%mm1           /* mm1 = mm0 */\n\t"
"	movd 124(%3),%%mm2      /* mm2 = c[0x1f] */\n\t"
"	punpckldq 120(%3),%%mm2 /* mm2 = c[0x1f] | c[0x1E] */\n\t"
"	pfadd %%mm2,%%mm0          /* mm0 = c[0x00]+c[0x1F] | c[0x1E]+c[0x01] */\n\t"
"	movq %%mm0,0(%0)        /* tmp[0, 1] = mm0 */\n\t"
"	pfsub %%mm2,%%mm1          /* c[0x00]-c[0x1f] | c[0x01]-c[0x1e] */\n\t"
"	pfmul 0(%%eax),%%mm1       /* (c[0x00]-c[0x1f])*pnts[0]|(c[0x01]-c[0x1e])*pnts[1]*/\n\t"
"	pswapd %%mm1, %%mm1        /* (c[0x01]-c[0x1e])*pnts[1]|(c[0x00]-c[0x1f])*pnts[0]*/\n\t"
"	movq   %%mm1, 120(%0)   /* tmp1[30, 31]=mm1 */\n\t"

"	movq 8(%3),%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 116(%3),%%mm6\n\t"
"	punpckldq 112(%3),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	movq %%mm4,8(%0)\n\t"
"	pfsub %%mm6,%%mm5\n\t"
"	pfmul 8(%%eax),%%mm5\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 112(%0)\n\t"

"	movq 16(%3),%%mm0\n\t"
"	movq %%mm0,%%mm1\n\t"
"	movd 108(%3),%%mm2\n\t"
"	punpckldq 104(%3),%%mm2\n\t"
"	pfadd %%mm2,%%mm0\n\t"
"	movq %%mm0,16(%0)\n\t"
"	pfsub %%mm2,%%mm1\n\t"
"	pfmul 16(%%eax),%%mm1\n\t"
"	pswapd %%mm1, %%mm1\n\t"
"	movq   %%mm1, 104(%0)\n\t"

"	movq 24(%3),%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 100(%3),%%mm6\n\t"
"	punpckldq 96(%3),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	movq %%mm4,24(%0)\n\t"
"	pfsub %%mm6,%%mm5\n\t"
"	pfmul 24(%%eax),%%mm5\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 96(%0)\n\t"

"	movq 32(%3),%%mm0\n\t"
"	movq %%mm0,%%mm1\n\t"
"	movd 92(%3),%%mm2\n\t"
"	punpckldq 88(%3),%%mm2\n\t"
"	pfadd %%mm2,%%mm0\n\t"
"	movq %%mm0,32(%0)\n\t"
"	pfsub %%mm2,%%mm1\n\t"
"	pfmul 32(%%eax),%%mm1\n\t"
"	pswapd %%mm1, %%mm1\n\t"
"	movq   %%mm1, 88(%0)\n\t"

"	movq 40(%3),%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 84(%3),%%mm6\n\t"
"	punpckldq 80(%3),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	movq %%mm4,40(%0)\n\t"
"	pfsub %%mm6,%%mm5\n\t"
"	pfmul 40(%%eax),%%mm5\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 80(%0)\n\t"

"	movq 48(%3),%%mm0\n\t"
"	movq %%mm0,%%mm1\n\t"
"	movd 76(%3),%%mm2\n\t"
"	punpckldq 72(%3),%%mm2\n\t"
"	pfadd %%mm2,%%mm0\n\t"
"	movq %%mm0,48(%0)\n\t"
"	pfsub %%mm2,%%mm1\n\t"
"	pfmul 48(%%eax),%%mm1\n\t"
"	pswapd %%mm1, %%mm1\n\t"
"	movq   %%mm1, 72(%0)\n\t"

"	movq 56(%3),%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 68(%3),%%mm6\n\t"
"	punpckldq 64(%3),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	movq %%mm4,56(%0)\n\t"
"	pfsub %%mm6,%%mm5\n\t"
"	pfmul 56(%%eax),%%mm5\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 64(%0)\n\t"

"	// 2\n\t"
"	movl "MANGLE(pnts)"+4,%%eax\n\t"
"	/ 0, 14\n\t"
"	movq 0(%0),%%mm0            /* mm0 = tmp1[0] | tmp1[1] */\n\t"
"	movq %%mm0,%%mm1\n\t"
"	movd 60(%0),%%mm2           /* mm2 = tmp1[0x0F] */\n\t"
"	punpckldq 56(%0),%%mm2      /* mm2 = tmp1[0x0E] | tmp1[0x0F] */\n\t"
"	movq 0(%%eax),%%mm3            /* mm3 = pnts[0] | pnts[1] */\n\t"
"	pfadd %%mm2,%%mm0              /* mm0 = tmp1[0]+tmp1[0x0F]|tmp1[1]+tmp1[0x0E]*/\n\t"
"	movq %%mm0,0(%4)            /* tmp2[0, 1] = mm0 */\n\t"
"	pfsub %%mm2,%%mm1              /* mm1 = tmp1[0]-tmp1[0x0F]|tmp1[1]-tmp1[0x0E]*/\n\t"
"	pfmul %%mm3,%%mm1              /* mm1 = (tmp1[0]-tmp1[0x0F])*pnts[0]|(tmp1[1]-tmp1[0x0E])*pnts[1]*/\n\t"
"	pswapd %%mm1, %%mm1            /* mm1 = (tmp1[1]-tmp1[0x0E])*pnts[1]|(tmp1[0]-tmp1[0x0F])*pnts[0]*/\n\t"
"	movq   %%mm1, 56(%4)        /* tmp2[0x0E, 0x0F] = mm1 */\n\t"
"	/ 16, 30\n\t"
"	movq 64(%0),%%mm0\n\t"
"	movq %%mm0,%%mm1\n\t"
"	movd 124(%0),%%mm2\n\t"
"	punpckldq 120(%0),%%mm2\n\t"
"	pfadd %%mm2,%%mm0\n\t"
"	movq %%mm0,64(%4)\n\t"
"	pfsubr %%mm2,%%mm1\n\t"
"	pfmul %%mm3,%%mm1\n\t"
"	pswapd %%mm1, %%mm1\n\t"
"	movq   %%mm1, 120(%4)\n\t"
"	movq 8(%0),%%mm4\n\t"
"	/ 2, 12\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 52(%0),%%mm6\n\t"
"	punpckldq 48(%0),%%mm6\n\t"
"	movq 8(%%eax),%%mm7\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	movq %%mm4,8(%4)\n\t"
"	pfsub %%mm6,%%mm5\n\t"
"	pfmul %%mm7,%%mm5\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 48(%4)\n\t"
"	movq 72(%0),%%mm4\n\t"
"	/ 18, 28\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 116(%0),%%mm6\n\t"
"	punpckldq 112(%0),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	movq %%mm4,72(%4)\n\t"
"	pfsubr %%mm6,%%mm5\n\t"
"	pfmul %%mm7,%%mm5\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 112(%4)\n\t"
"	movq 16(%0),%%mm0\n\t"
"	/ 4, 10\n\t"
"	movq %%mm0,%%mm1\n\t"
"	movd 44(%0),%%mm2\n\t"
"	punpckldq 40(%0),%%mm2\n\t"
"	movq 16(%%eax),%%mm3\n\t"
"	pfadd %%mm2,%%mm0\n\t"
"	movq %%mm0,16(%4)\n\t"
"	pfsub %%mm2,%%mm1\n\t"
"	pfmul %%mm3,%%mm1\n\t"
"	pswapd %%mm1, %%mm1\n\t"
"	movq   %%mm1, 40(%4)\n\t"
"	movq 80(%0),%%mm0\n\t"
"	/ 20, 26\n\t"
"	movq %%mm0,%%mm1\n\t"
"	movd 108(%0),%%mm2\n\t"
"	punpckldq 104(%0),%%mm2\n\t"
"	pfadd %%mm2,%%mm0\n\t"
"	movq %%mm0,80(%4)\n\t"
"	pfsubr %%mm2,%%mm1\n\t"
"	pfmul %%mm3,%%mm1\n\t"
"	pswapd %%mm1, %%mm1\n\t"
"	movq   %%mm1, 104(%4)\n\t"
"	movq 24(%0),%%mm4\n\t"
"	/ 6, 8\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 36(%0),%%mm6\n\t"
"	punpckldq 32(%0),%%mm6\n\t"
"	movq 24(%%eax),%%mm7\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	movq %%mm4,24(%4)\n\t"
"	pfsub %%mm6,%%mm5\n\t"
"	pfmul %%mm7,%%mm5\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 32(%4)\n\t"
"	movq 88(%0),%%mm4\n\t"
"	/ 22, 24\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 100(%0),%%mm6\n\t"
"	punpckldq 96(%0),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	movq %%mm4,88(%4)\n\t"
"	pfsubr %%mm6,%%mm5\n\t"
"	pfmul %%mm7,%%mm5\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 96(%4)\n\t"

"	// 3\n\t"
"	movl "MANGLE(pnts)"+8,%%eax\n\t"
"	movq 0(%%eax),%%mm0\n\t"
"	movq 8(%%eax),%%mm1\n\t"
"	movq 0(%4),%%mm2\n\t"
"	/ 0, 6\n\t"
"	movq %%mm2,%%mm3\n\t"
"	movd 28(%4),%%mm4\n\t"
"	punpckldq 24(%4),%%mm4\n\t"
"	pfadd %%mm4,%%mm2\n\t"
"	pfsub %%mm4,%%mm3\n\t"
"	pfmul %%mm0,%%mm3\n\t"
"	movq %%mm2,0(%0)\n\t"
"	pswapd %%mm3, %%mm3\n\t"
"	movq   %%mm3, 24(%0)\n\t"
"	movq 8(%4),%%mm5\n\t"
"	/ 2, 4\n\t"
"	movq %%mm5,%%mm6\n\t"
"	movd 20(%4),%%mm7\n\t"
"	punpckldq 16(%4),%%mm7\n\t"
"	pfadd %%mm7,%%mm5\n\t"
"	pfsub %%mm7,%%mm6\n\t"
"	pfmul %%mm1,%%mm6\n\t"
"	movq %%mm5,8(%0)\n\t"
"	pswapd %%mm6, %%mm6\n\t"
"	movq   %%mm6, 16(%0)\n\t"
"	movq 32(%4),%%mm2\n\t"
"	/ 8, 14\n\t"
"	movq %%mm2,%%mm3\n\t"
"	movd 60(%4),%%mm4\n\t"
"	punpckldq 56(%4),%%mm4\n\t"
"	pfadd %%mm4,%%mm2\n\t"
"	pfsubr %%mm4,%%mm3\n\t"
"	pfmul %%mm0,%%mm3\n\t"
"	movq %%mm2,32(%0)\n\t"
"	pswapd %%mm3, %%mm3\n\t"
"	movq   %%mm3, 56(%0)\n\t"
"	movq 40(%4),%%mm5\n\t"
"	/ 10, 12\n\t"
"	movq %%mm5,%%mm6\n\t"
"	movd 52(%4),%%mm7\n\t"
"	punpckldq 48(%4),%%mm7\n\t"
"	pfadd %%mm7,%%mm5\n\t"
"	pfsubr %%mm7,%%mm6\n\t"
"	pfmul %%mm1,%%mm6\n\t"
"	movq %%mm5,40(%0)\n\t"
"	pswapd %%mm6, %%mm6\n\t"
"	movq   %%mm6, 48(%0)\n\t"
"	movq 64(%4),%%mm2\n\t"
"	/ 16, 22\n\t"
"	movq %%mm2,%%mm3\n\t"
"	movd 92(%4),%%mm4\n\t"
"	punpckldq 88(%4),%%mm4\n\t"
"	pfadd %%mm4,%%mm2\n\t"
"	pfsub %%mm4,%%mm3\n\t"
"	pfmul %%mm0,%%mm3\n\t"
"	movq %%mm2,64(%0)\n\t"
"	pswapd %%mm3, %%mm3\n\t"
"	movq   %%mm3, 88(%0)\n\t"
"	movq 72(%4),%%mm5\n\t"
"	/ 18, 20\n\t"
"	movq %%mm5,%%mm6\n\t"
"	movd 84(%4),%%mm7\n\t"
"	punpckldq 80(%4),%%mm7\n\t"
"	pfadd %%mm7,%%mm5\n\t"
"	pfsub %%mm7,%%mm6\n\t"
"	pfmul %%mm1,%%mm6\n\t"
"	movq %%mm5,72(%0)\n\t"
"	pswapd %%mm6, %%mm6\n\t"
"	movq   %%mm6, 80(%0)\n\t"
"	movq 96(%4),%%mm2\n\t"
"	/ 24, 30\n\t"
"	movq %%mm2,%%mm3\n\t"
"	movd 124(%4),%%mm4\n\t"
"	punpckldq 120(%4),%%mm4\n\t"
"	pfadd %%mm4,%%mm2\n\t"
"	pfsubr %%mm4,%%mm3\n\t"
"	pfmul %%mm0,%%mm3\n\t"
"	movq %%mm2,96(%0)\n\t"
"	pswapd %%mm3, %%mm3\n\t"
"	movq   %%mm3, 120(%0)\n\t"
"	movq 104(%4),%%mm5\n\t"
"	/ 26, 28\n\t"
"	movq %%mm5,%%mm6\n\t"
"	movd 116(%4),%%mm7\n\t"
"	punpckldq 112(%4),%%mm7\n\t"
"	pfadd %%mm7,%%mm5\n\t"
"	pfsubr %%mm7,%%mm6\n\t"
"	pfmul %%mm1,%%mm6\n\t"
"	movq %%mm5,104(%0)\n\t"
"	pswapd %%mm6, %%mm6\n\t"
"	movq   %%mm6, 112(%0)\n\t"

"	// 4\n\t"
"	movl "MANGLE(pnts)"+12,%%eax    \n\t"
"	movq 0(%%eax),%%mm0      /* mm0 = pnts[3] | pnts[4] */\n\t"
"	movq 0(%0),%%mm1      /* mm1 = tmp1[0] | tmp1[1] */\n\t"
"	/ 0\n\t"
"	movq %%mm1,%%mm2\n\t"
"	movd 12(%0),%%mm3     /* mm3 = tmp1[3] */\n\t"
"	punpckldq 8(%0),%%mm3 /* mm3 = tmp1[3] | tmp1[2] */\n\t"
"	pfadd %%mm3,%%mm1        /* mm1 = tmp1[0]+tmp1[3] | tmp1[1]+tmp1[2]*/\n\t"
"	pfsub %%mm3,%%mm2        /* mm2 = tmp1[0]-tmp1[3] | tmp1[0]-tmp1[2]*/\n\t"
"	pfmul %%mm0,%%mm2        /* mm2 = tmp1[0]-tmp1[3]*pnts[3]|tmp1[0]-tmp1[2]*pnts[4]*/\n\t"
"	movq %%mm1,0(%4)      /* tmp2[0, 1] = mm1 */\n\t"
"	pswapd %%mm2, %%mm2      /* mm2 = tmp1[0]-tmp1[2]*pnts[4]|tmp1[0]-tmp1[3]*pnts[3] */\n\t"
"	movq   %%mm2, 8(%4)   /* tmp2[2, 3] = mm2 */\n\t"
"	movq 16(%0),%%mm4\n\t"
"	/ 4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 28(%0),%%mm6\n\t"
"	punpckldq 24(%0),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	pfsubr %%mm6,%%mm5\n\t"
"	pfmul %%mm0,%%mm5\n\t"
"	movq %%mm4,16(%4)\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 24(%4)\n\t"
"	movq 32(%0),%%mm1\n\t"
"	/ 8\n\t"
"	movq %%mm1,%%mm2\n\t"
"	movd 44(%0),%%mm3\n\t"
"	punpckldq 40(%0),%%mm3\n\t"
"	pfadd %%mm3,%%mm1\n\t"
"	pfsub %%mm3,%%mm2\n\t"
"	pfmul %%mm0,%%mm2\n\t"
"	movq %%mm1,32(%4)\n\t"
"	pswapd %%mm2, %%mm2\n\t"
"	movq   %%mm2, 40(%4)\n\t"
"	movq 48(%0),%%mm4\n\t"
"	/ 12\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 60(%0),%%mm6\n\t"
"	punpckldq 56(%0),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	pfsubr %%mm6,%%mm5\n\t"
"	pfmul %%mm0,%%mm5\n\t"
"	movq %%mm4,48(%4)\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 56(%4)\n\t"
"	movq 64(%0),%%mm1\n\t"
"	/ 16\n\t"
"	movq %%mm1,%%mm2\n\t"
"	movd 76(%0),%%mm3\n\t"
"	punpckldq 72(%0),%%mm3\n\t"
"	pfadd %%mm3,%%mm1\n\t"
"	pfsub %%mm3,%%mm2\n\t"
"	pfmul %%mm0,%%mm2\n\t"
"	movq %%mm1,64(%4)\n\t"
"	pswapd %%mm2, %%mm2\n\t"
"	movq   %%mm2, 72(%4)\n\t"
"	movq 80(%0),%%mm4\n\t"
"	/ 20\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 92(%0),%%mm6\n\t"
"	punpckldq 88(%0),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	pfsubr %%mm6,%%mm5\n\t"
"	pfmul %%mm0,%%mm5\n\t"
"	movq %%mm4,80(%4)\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 88(%4)\n\t"
"	movq 96(%0),%%mm1\n\t"
"	/ 24\n\t"
"	movq %%mm1,%%mm2\n\t"
"	movd 108(%0),%%mm3\n\t"
"	punpckldq 104(%0),%%mm3\n\t"
"	pfadd %%mm3,%%mm1\n\t"
"	pfsub %%mm3,%%mm2\n\t"
"	pfmul %%mm0,%%mm2\n\t"
"	movq %%mm1,96(%4)\n\t"
"	pswapd %%mm2, %%mm2\n\t"
"	movq   %%mm2, 104(%4)\n\t"
"	movq 112(%0),%%mm4\n\t"
"	/ 28\n\t"
"	movq %%mm4,%%mm5\n\t"
"	movd 124(%0),%%mm6\n\t"
"	punpckldq 120(%0),%%mm6\n\t"
"	pfadd %%mm6,%%mm4\n\t"
"	pfsubr %%mm6,%%mm5\n\t"
"	pfmul %%mm0,%%mm5\n\t"
"	movq %%mm4,112(%4)\n\t"
"	pswapd %%mm5, %%mm5\n\t"
"	movq   %%mm5, 120(%4)\n\t"

"	// 5\n\t"
"	movq "MANGLE(plus_minus_3dnow)", %%mm0 /* mm0 = 1.0 | -1.0 */\n\t"
"	movl $1,%%eax\n\t"
"	movd %%eax,%%mm1\n\t"
"	pi2fd %%mm1,%%mm1\n\t"
"	movl "MANGLE(pnts)"+16,%%eax\n\t"
"	movd 0(%%eax),%%mm2\n\t"
"	punpckldq %%mm2,%%mm1   /* mm1 = 1.0 | cos0 */\n\t"
"	movq 0(%4),%%mm2     /* mm2 = tmp2[0] | tmp2[1] */\n\t"
"	/ 0\n\t"
"	pfpnacc %%mm2, %%mm2\n\t"
"	pswapd %%mm2, %%mm2     /* mm2 = tmp2[0]+tmp2[1]|tmp2[0]-tmp2[1]*/\n\t"
"	pfmul %%mm1,%%mm2       /* mm2 = tmp2[0]+tmp2[1]|(tmp2[0]-tmp2[1])*cos0*/\n\t"
"	movq %%mm2,0(%0)     /* tmp1[0, 1] = mm2 */\n\t"
"	movq 8(%4),%%mm4     /* mm4 = tmp2[2] | tmp2[3]*/\n\t"
"	pfpnacc %%mm4, %%mm4\n\t"
"	pswapd  %%mm4, %%mm4    /* mm4 = tmp2[2]+tmp2[3]|tmp2[2]-tmp2[3]*/\n\t"
"	pxor  %%mm0,%%mm4       /* mm4 = tmp2[2]+tmp2[3]|tmp2[3]-tmp2[2]*/\n\t"
"	pfmul %%mm1,%%mm4       /* mm4 = tmp2[2]+tmp2[3]|(tmp2[3]-tmp2[2])*cos0*/\n\t"
"	movq %%mm4,%%mm5\n\t"
"	psrlq $32,%%mm5        /* mm5 = (tmp2[3]-tmp2[2])*cos0 */\n\t"
"	pfacc %%mm5,%%mm4       /* mm4 = tmp2[2]+tmp2[3]+(tmp2[3]-tmp2[2])*cos0|(tmp2[3]-tmp2[2])*cos0*/\n\t"
"	movq %%mm4,8(%0)     /* tmp1[2, 3] = mm4 */\n\t"
"	movq 16(%4),%%mm2\n\t"
"	/ 4\n\t"
"	pfpnacc %%mm2, %%mm2\n\t"
"	pswapd %%mm2, %%mm2\n\t"

"	pfmul %%mm1,%%mm2\n\t"
"	movq 24(%4),%%mm4\n\t"
"	pfpnacc %%mm4, %%mm4\n\t"
"	pswapd  %%mm4, %%mm4\n\t"

"	pxor  %%mm0,%%mm4\n\t"
"	pfmul %%mm1,%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	psrlq $32,%%mm5\n\t"
"	pfacc %%mm5,%%mm4\n\t"
"	movq %%mm2,%%mm3\n\t"
"	psrlq $32,%%mm3\n\t"
"	pfadd %%mm4,%%mm2\n\t"
"	pfadd %%mm3,%%mm4\n\t"
"	movq %%mm2,16(%0)\n\t"
"	movq %%mm4,24(%0)\n\t"
"	movq 32(%4),%%mm2\n\t"
"	/ 8\n\t"
"	pfpnacc %%mm2, %%mm2\n\t"
"	pswapd %%mm2, %%mm2\n\t"

"	pfmul %%mm1,%%mm2\n\t"
"	movq %%mm2,32(%0)\n\t"
"	movq 40(%4),%%mm4\n\t"
"	pfpnacc %%mm4, %%mm4\n\t"
"	pswapd  %%mm4, %%mm4\n\t"
"	pxor  %%mm0,%%mm4\n\t"
"	pfmul %%mm1,%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	psrlq $32,%%mm5\n\t"
"	pfacc %%mm5,%%mm4\n\t"
"	movq %%mm4,40(%0)\n\t"
"	movq 48(%4),%%mm2\n\t"
"	/ 12\n\t"
"	pfpnacc %%mm2, %%mm2\n\t"
"	pswapd %%mm2, %%mm2\n\t"
"	pfmul %%mm1,%%mm2\n\t"
"	movq 56(%4),%%mm4\n\t"
"	pfpnacc %%mm4, %%mm4\n\t"
"	pswapd  %%mm4, %%mm4\n\t"
"	pxor  %%mm0,%%mm4\n\t"
"	pfmul %%mm1,%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	psrlq $32,%%mm5\n\t"
"	pfacc %%mm5,%%mm4\n\t"
"	movq %%mm2,%%mm3\n\t"
"	psrlq $32,%%mm3\n\t"
"	pfadd %%mm4,%%mm2\n\t"
"	pfadd %%mm3,%%mm4\n\t"
"	movq %%mm2,48(%0)\n\t"
"	movq %%mm4,56(%0)\n\t"
"	movq 64(%4),%%mm2\n\t"
"	/ 16\n\t"
"	pfpnacc %%mm2, %%mm2\n\t"
"	pswapd %%mm2, %%mm2\n\t"
"	pfmul %%mm1,%%mm2\n\t"
"	movq %%mm2,64(%0)\n\t"
"	movq 72(%4),%%mm4\n\t"
"	pfpnacc %%mm4, %%mm4\n\t"
"	pswapd  %%mm4, %%mm4\n\t"
"	pxor  %%mm0,%%mm4\n\t"
"	pfmul %%mm1,%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	psrlq $32,%%mm5\n\t"
"	pfacc %%mm5,%%mm4\n\t"
"	movq %%mm4,72(%0)\n\t"
"	movq 80(%4),%%mm2\n\t"
"	/ 20\n\t"
"	pfpnacc %%mm2, %%mm2\n\t"
"	pswapd %%mm2, %%mm2\n\t"
"	pfmul %%mm1,%%mm2\n\t"
"	movq 88(%4),%%mm4\n\t"
"	pfpnacc %%mm4, %%mm4\n\t"
"	pswapd  %%mm4, %%mm4\n\t"
"	pxor  %%mm0,%%mm4\n\t"
"	pfmul %%mm1,%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	psrlq $32,%%mm5\n\t"
"	pfacc %%mm5,%%mm4\n\t"
"	movq %%mm2,%%mm3\n\t"
"	psrlq $32,%%mm3\n\t"
"	pfadd %%mm4,%%mm2\n\t"
"	pfadd %%mm3,%%mm4\n\t"
"	movq %%mm2,80(%0)\n\t"
"	movq %%mm4,88(%0)\n\t"
"	movq 96(%4),%%mm2\n\t"
"	/ 24\n\t"
"	pfpnacc %%mm2, %%mm2\n\t"
"	pswapd %%mm2, %%mm2\n\t"
"	pfmul %%mm1,%%mm2\n\t"
"	movq %%mm2,96(%0)\n\t"
"	movq 104(%4),%%mm4\n\t"
"	pfpnacc %%mm4, %%mm4\n\t"
"	pswapd  %%mm4, %%mm4\n\t"
"	pxor  %%mm0,%%mm4\n\t"
"	pfmul %%mm1,%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	psrlq $32,%%mm5\n\t"
"	pfacc %%mm5,%%mm4\n\t"
"	movq %%mm4,104(%0)\n\t"
"	movq 112(%4),%%mm2\n\t"
"	/ 28\n\t"
"	pfpnacc %%mm2, %%mm2\n\t"
"	pswapd %%mm2, %%mm2\n\t"
"	pfmul %%mm1,%%mm2\n\t"
"	movq 120(%4),%%mm4\n\t"
"	pfpnacc %%mm4, %%mm4\n\t"
"	pswapd  %%mm4, %%mm4\n\t"
"	pxor  %%mm0,%%mm4\n\t"
"	pfmul %%mm1,%%mm4\n\t"
"	movq %%mm4,%%mm5\n\t"
"	psrlq $32,%%mm5\n\t"
"	pfacc %%mm5,%%mm4\n\t"
"	movq %%mm2,%%mm3\n\t"
"	psrlq $32,%%mm3\n\t"
"	pfadd %%mm4,%%mm2\n\t"
"	pfadd %%mm3,%%mm4\n\t"
"	movq %%mm2,112(%0)\n\t"
"	movq %%mm4,120(%0)\n\t"

"	// Phase6\n\t"
"	movd 0(%0),%%mm0\n\t"
"	movd %%mm0,1024(%1)\n\t"
"	movl 4(%0),%%eax\n\t"
"	movl %%eax,0(%1)\n\t"
"	movl %%eax,0(%2)\n\t"
"	movd 8(%0),%%mm2\n\t"
"	movd %%mm2,512(%1)\n\t"
"	movd 12(%0),%%mm3\n\t"
"	movd %%mm3,512(%2)\n\t"

"	movl 16(%0),%%eax\n\t"
"	movl %%eax,768(%1)\n\t"
"	movd 20(%0),%%mm5\n\t"
"	movd %%mm5,256(%2)\n\t"

"	movd 24(%0),%%mm6\n\t"
"	movd %%mm6,256(%1)\n\t"
"	movd 28(%0),%%mm7\n\t"
"	movd %%mm7,768(%2)\n\t"

"	movq 32(%0),%%mm0       /* mm0 = tmp1[8] | tmp1[9] */\n\t"
"	movq 48(%0),%%mm1       /* mm1 = tmp1[12] | tmp1[13] */\n\t"
"	pfadd %%mm1,%%mm0          /* mm0 = tmp1[8]+tmp1[12]| tmp1[9]+tmp1[13]*/\n\t"
"	movd %%mm0,896(%1)      /* a[0xE0] = tmp1[8]+tmp1[12] */\n\t"
"	psrlq $32,%%mm0\n\t"
"	movd %%mm0,128(%2)      /* a[0x20] = tmp1[9]+tmp1[13] */\n\t"
"	movq 40(%0),%%mm2\n\t"
"	pfadd %%mm2,%%mm1\n\t"
"	movd %%mm1,640(%1)\n\t"
"	psrlq $32,%%mm1\n\t"
"	movd %%mm1,384(%2)\n\t"

"	movq 56(%0),%%mm3\n\t"
"	pfadd %%mm3,%%mm2\n\t"
"	movd %%mm2,384(%1)\n\t"
"	psrlq $32,%%mm2\n\t"
"	movd %%mm2,640(%2)\n\t"

"	movd 36(%0),%%mm4\n\t"
"	pfadd %%mm4,%%mm3\n\t"
"	movd %%mm3,128(%1)\n\t"
"	psrlq $32,%%mm3\n\t"
"	movd %%mm3,896(%2)\n\t"
"	movq 96(%0),%%mm0\n\t"
"	movq 64(%0),%%mm1\n\t"

"	movq 112(%0),%%mm2\n\t"
"	pfadd %%mm2,%%mm0\n\t"
"	movq %%mm0,%%mm3\n\t"
"	pfadd %%mm1,%%mm3\n\t"
"	movd %%mm3,960(%1)\n\t"
"	psrlq $32,%%mm3\n\t"
"	movd %%mm3,64(%2)\n\t"
"	movq 80(%0),%%mm1\n\t"
"	pfadd %%mm1,%%mm0\n\t"
"	movd %%mm0,832(%1)\n\t"
"	psrlq $32,%%mm0\n\t"
"	movd %%mm0,192(%2)\n\t"
"	movq 104(%0),%%mm3\n\t"
"	pfadd %%mm3,%%mm2\n\t"
"	movq %%mm2,%%mm4\n\t"
"	pfadd %%mm1,%%mm4\n\t"
"	movd %%mm4,704(%1)\n\t"
"	psrlq $32,%%mm4\n\t"
"	movd %%mm4,320(%2)\n\t"
"	movq 72(%0),%%mm1\n\t"
"	pfadd %%mm1,%%mm2\n\t"
"	movd %%mm2,576(%1)\n\t"
"	psrlq $32,%%mm2\n\t"
"	movd %%mm2,448(%2)\n\t"

"	movq 120(%0),%%mm4\n\t"
"	pfadd %%mm4,%%mm3\n\t"
"	movq %%mm3,%%mm5\n\t"
"	pfadd %%mm1,%%mm5\n\t"
"	movd %%mm5,448(%1)\n\t"
"	psrlq $32,%%mm5\n\t"
"	movd %%mm5,576(%2)\n\t"
"	movq 88(%0),%%mm1\n\t"
"	pfadd %%mm1,%%mm3\n\t"
"	movd %%mm3,320(%1)\n\t"
"	psrlq $32,%%mm3\n\t"
"	movd %%mm3,704(%2)\n\t"

"	movd 100(%0),%%mm5\n\t"
"	pfadd %%mm5,%%mm4\n\t"
"	movq %%mm4,%%mm6\n\t"
"	pfadd %%mm1,%%mm6\n\t"
"	movd %%mm6,192(%1)\n\t"
"	psrlq $32,%%mm6\n\t"
"	movd %%mm6,832(%2)\n\t"
"	movd 68(%0),%%mm1\n\t"
"	pfadd %%mm1,%%mm4\n\t"
"	movd %%mm4,64(%1)\n\t"
"	psrlq $32,%%mm4\n\t"
"	movd %%mm4,960(%2)"
	::"r"(&tmp[0]),"r"(a), "r"(b), "r"(c), "r"(&tmp[128])
	:"memory","%eax"
#ifdef FPU_CLOBBERED
	,FPU_CLOBBERED
#endif
#ifdef MMX_CLOBBERED
	,MMX_CLOBBERED
#endif
	);
    return;
}
